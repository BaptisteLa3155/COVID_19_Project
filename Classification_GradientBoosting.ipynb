{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('CSV_Creation/OECD_countries_data.csv') as f:\n",
    "    overall_data_by_country = pd.read_csv(f, error_bad_lines=False)\n",
    "\n",
    "#we want to predict Death_rate by using countries' features \n",
    "features = list(overall_data_by_country.columns)\n",
    "features.remove('Death_rate')\n",
    "features.remove('Country')\n",
    "overall_data_by_country = overall_data_by_country.set_index('Country')\n",
    "\n",
    "#countries are classified according their death rate. Countries with the label 'True' means \n",
    "#that these countries have a high mortality rate compare to other countries\n",
    "\n",
    "def classify_countries(threshold, overall_data_by_country):\n",
    "    death_rate_class = []\n",
    "    for i in range(overall_data_by_country.shape[0]):\n",
    "        if overall_data_by_country.values[i,0] > threshold:\n",
    "            death_rate_class.append(True)\n",
    "        else:\n",
    "            death_rate_class.append(False)\n",
    "    return np.array(death_rate_class)\n",
    "\n",
    "death_rate_class = classify_countries(8, overall_data_by_country) #the label (y)\n",
    "other_data = overall_data_by_country[features].values #features to find the label (X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#separating the data for training and testing \n",
    "train_death_rate, test_death_rate, train_other_data, test_other_data = train_test_split(death_rate_class, other_data, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#building of the model\n",
    "Gbc = GradientBoostingClassifier()\n",
    "cv = KFold(n_splits=5)\n",
    "\n",
    "Gbc.fit(train_other_data, train_death_rate)\n",
    "pred_death_rate = Gbc.predict(test_other_data)\n",
    "pred_train = Gbc.predict(train_other_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n",
      "Precision: 1.0\n",
      "Recall:  1.0\n"
     ]
    }
   ],
   "source": [
    "#tool to assess the model with the training dataset\n",
    "print('Accuracy:', metrics.accuracy_score(train_death_rate, pred_train))\n",
    "print('Precision:', metrics.precision_score(train_death_rate, pred_train))\n",
    "print('Recall: ', metrics.recall_score(train_death_rate, pred_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.875\n",
      "Precision: 0.6666666666666666\n",
      "Recall:  1.0\n",
      "[[5 1]\n",
      " [0 2]]\n"
     ]
    }
   ],
   "source": [
    "#tools to assess the model with the test dataset \n",
    "print('Accuracy:', metrics.accuracy_score(test_death_rate, pred_death_rate))\n",
    "print('Precision:', metrics.precision_score(test_death_rate, pred_death_rate))\n",
    "print('Recall: ', metrics.recall_score(test_death_rate, pred_death_rate))\n",
    "print(metrics.confusion_matrix(test_death_rate, pred_death_rate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tests per confirmed cases    0.675798\n",
      "Proportion of edler people             0.224285\n",
      "Proportion of overweight people        0.034324\n",
      "Health employment per 1000 hab         0.033348\n",
      "Hospital beds per 1000 hab             0.032245\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#contributions of the feature for classifying the data\n",
    "feature_imp = pd.Series(Gbc.feature_importances_,index=features).sort_values(ascending=False)\n",
    "print(feature_imp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this function return 3 lists of metrics obtained by cross validation\n",
    "def build_list_scores(Method, X, y):\n",
    "    accuracies = []\n",
    "    recalls = []\n",
    "    precisions = []\n",
    "    for i, (train, test) in enumerate(cv.split(X,y)):\n",
    "        Method.fit(X[train], y[train])\n",
    "        y_pred = Method.predict(X[test])\n",
    "        accuracies.append(metrics.accuracy_score(y[test], y_pred))\n",
    "        if True in y[test]:#test dataset can have no postive sample due to the imbalance\n",
    "            recalls.append(metrics.recall_score(y[test], y_pred))\n",
    "        else: \n",
    "            recalls.append(np.nan)\n",
    "        if True in y_pred:#predictions can have no positive results \n",
    "            precisions.append(metrics.precision_score(y[test], y_pred))\n",
    "        else:\n",
    "            precisions.append(np.nan)\n",
    "    return (accuracies, recalls, precisions)\n",
    "            \n",
    "(accuracies, recalls, precisions) = build_list_scores(Gbc, other_data, death_rate_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of predictions whithout positive results: 1\n",
      "The average accuracy is: 0.78 +/- 0.15\n",
      "The average recall is: 0.60 +/- 0.37\n",
      "The average precision is: 0.69 +/- 0.32\n"
     ]
    }
   ],
   "source": [
    "print('Number of predictions whithout positive results:',len([i for i in precisions if i is np.nan]))\n",
    "print('The average accuracy is: %0.2f +/- %0.2f' %(np.nanmean(accuracies), np.nanstd(accuracies)))\n",
    "print('The average recall is: %0.2f +/- %0.2f' %(np.nanmean(recalls), np.nanstd(recalls)))\n",
    "print('The average precision is: %0.2f +/- %0.2f' %(np.nanmean(precisions), np.nanstd(precisions)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
